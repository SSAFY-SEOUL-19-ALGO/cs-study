# 대규모 트래픽 처리를 통해 서버 과부하 해결 방법

## 서버 과부하란?
서버의 리소스가 소진되어 들어오는 요청을 처리하지 못하는것. 이용자 수가 많아져 서버의 리소스가 부족해 지거나, 한번에 많은 요청이 동시에 들어와 서버 과부하가 발생되는 경우를 생각할 수 있다.

## 서버 모니터링이란?
- 실시간으로 운영 상황 파악 및 문제상황 파악 가능
- 서버 자원과 네트워크에 상관관계 분석 가능
- 클라우드 사용시 병목으로 인한 과부하 방지
- 활용도가 높은 페이지와 낮은 페이지를 분석하여 서비스 개선
- CPU, Memory, Disk IO, Disk사용량, 네트워크 속도등 체크
- AWS Auto Scaling은 애플리케이션을 모니터링하고 용량을 자동으로 조정 (scale out 방식)

## 로드 벨런서
1. 분산처리
   - 많은 리퀘스트를 복수의 서버에 분산시켜 처리하는것
   - 복수의 서버를 설치하고, 부하 분산 장치로써 로드벨런서를 사용해 로드 벨런싱(해야 할 작업들을 나누어 서버의 부하를 분산)을 수행함
2. 로드벨런싱 알고리즘
   - 라운드 로빈 방식
     - 리퀘스트를 순서대로 서버들에 할당하는 방식
     - 서버들의 성능이 동일하고, 처리 시간이 짧은 애플리케이션일때 사용
   - 가중 라운드 로빈 방식
     - 서버에 서로다른 처리 용량을 지정하는 방식 
   - 최소 연결 방식
     - 연결 수가 가장 적은 서버에 할당
     - 동적으로 변하는 요청에 대한 부하를 분산시킬 수 있다
3. 로드벨런서 종류
   - L4(NLB) : Transport 계층을 사용, IP 주소와 포트 번호 부하 분산이 가능
     - 서버로 들어오는 트래픽은 Load Balancer를 통하고 나가는 트래픽은 Client IP와 직접 통신
     - Client → Server에서 Access 제한 가능
   - L7(ALB): L7 : Application 계층을 사용, URL 또는 HTTP 헤더에서 부하 분산이 가능
     - Reverse Proxy 대로 Client IP와 서버사이에 들어오고 나가는 트래픽이 모두 Load Balancer 와 통신
    <img width="841" alt="스크린샷 2023-01-15 오후 4 02 27" src="https://user-images.githubusercontent.com/55372995/212527549-fdc78e5d-564f-4b0c-b47f-c5b09881b505.png">
     - Client → Load Balancer의 Access 제한 가능

< 참고 링크 >
https://dev.classmethod.jp/articles/load-balancing-types-and-algorithm/

## 서킷 브레이커
MSA에서 한 서비스가 오류가 생길 때 의존관계가 있는 다른 서비스까지 장애 cascading이 생길 수 있다. 이것을 막기위해 외부 서비스와 연결을 차단하고 복구하는 과정을 서킷 브레이커라 한다. 
- 서킷 브레이커는 몇가지 상태값을 갖는다
  - closed: 네트워크 요청의 실패율이 임계치보다 낮다 -> 정상
  - open: 임계치 이상의 상태, 요청 전송을 하지 않고 바로 오류를 반환 (fail fast)
  - half_open: open 상태에서 일정한 설정된 시간이 지난 후 장애가 해결되었는지 확인하는 상태. 장애가 풀렸으면 closed상태로 전환 

## CDN(Content Delivery Network)
사용자 가까이, 혹은 분산된 대규모 서버 네트워크를 기반으로 컨텐츠를 제공하여 메인 서버에 대한 부하를 줄인다.

## 캐싱
브라우저 캐시를 통해 반복된 요청에 대한 응답을 네트워크를 타지 않고 제공

## 컨텐츠 압축
텍스트 기반 리소스를 gzip등으로 압축하여 제공
