# 캐시, 캐시히트, 캐시미스, 캐시의 사례

**캐시 ( Cache )**

프랑스어로 물건을 일시적으로 저장, 보관하기 위해 사용하는 곳

**컴퓨터 과학에서의 캐시**

자주 필요한 데이터나 값의 복사본을 일시적으로 저장, 보관하기 위해 사용하는 곳

**캐싱 ( Caching)**

캐시를 사용하는 것

캐싱은 하드웨어에만 존재하는 것이 아니라 운영체제, 네트워크 웹 어플리케이션, DB 등 다양하게 적용되고 있다

하지만 캐싱의 목적과 역할은 모두 크게 다르지 않다

**캐시 메모리**

[ 컴퓨터 동작 흐름 ]

![image](https://user-images.githubusercontent.com/96561194/214806799-e6111957-ebce-463e-b42e-576841c420b5.png)

(RAM , Hard Drive 속도차 약 10만배)

CPU는 데이터 처리를 위해 메모리와 끊임없이 데이터를 주고받는다

데이터 처리 속도 차이가 매우 커 메모리가 CPU의 데이터 처리 속도를 따라가지 못함

CPU가 메모리를 기다려야하는 병목현상이 발생

이러한 병목현상을 완화하기 위해 CPU와 메인 메모리 사이에 캐시메모리를 둠

캐시 메모리를 크기는 작지만 속도는 빠른 메모리로 캐시 메모리에 향후 재사용 가능성이 클 것으로 예상되는 데이터의 복사본을 저장 해 놓은 후 CPU가 요청하면 해당 데이터를 전달함

왜 속도가 빠른 캐시메모리를 메인 메모리 대신 사용하지 않을까?

![image](https://user-images.githubusercontent.com/96561194/214806852-039ff375-45ea-480e-b555-539eda17f315.png)
한 셀당 차지하는 트랜지스터 개수 차이가 매우큼

즉 동일용량 대비 메인메모리와 캐시메모리의 가격차이가 심하기 때문에 대체하지 못함

\*번외

캐시메모리는 CPU 내부에 존재한다 따로 부품이 존재하는것이 아님

![image](https://user-images.githubusercontent.com/96561194/214806920-51591a8d-62de-4c11-8f65-16c84dbd9d9b.png)

위에서는 CPU와 메인 메모리에 대한 캐싱만 설명했지만 캐싱은 CPU 메인 메모리에서만 작용되는 것이 아니다

한 계층은 바로 아래 계층에 대하여 캐싱 작업을 수행한다

ex) 캐시 → 메인메모리 캐싱, 메인 메모리 → 보조 메모리 캐싱 등등

이렇게 캐싱을 할 때 사용되는 캐시에는 재사용성이 큰 데이터를 올리는데

재사용성이 큰 데이터는 데이터 지역성 원리라는 것을 사용해 판단한다

**시간 지역성**

특정 데이터가 한번 접근되었을 경우, 가까운 미래에 또 한번 데이터에 접근할 가능성이 높은 것

메모리 상의 같은 주소에 여러차례 읽기 쓰기를 수행할 경우 상대적으로 작은 크기의 캐시를 사용해도 효율성을 높일 수 있음

**공간 지역성**

특정 데이터와 가까운 주소가 순서대로 접근되는 경우

한 메모리 주소에 접근할 때 그 주소뿐 아니라 해당 블록을 전부 캐시에 가져온다

이때 메모리 주소를 오름차순 혹은 내림차순으로 접근한다면, 이미 캐시에 저장된 같은 블록의 데이터에 접근하게 되므로 캐시의 효율성이 크게 향상된다

ex)

```java
int [] arr = new int[10];
for(int i=0; i<10; i++){  // <- 변수 i에 계속해서 접근함 , 시간 지역성
	arr[i] = i;  // <- arr 이라는 배열 주소에 계속 해서 접근, 공간 지역성
}
```

데이터의 지역성 원리를 사용해 캐시에 데이터를 넣었다면 CPU가 메모리에 데이터를 요청할 때 메인 메모리에 접근하기 전 캐시 메모리에 접근하여 데이터의 존재를 확인하는데 이 때 캐시메모리가 해당 데이터를 갖고 있다면 캐시히트 없다면 캐시미스 라고 함

![image](https://user-images.githubusercontent.com/96561194/214806981-16367075-1327-4fef-b071-2b13e6509157.png)
캐시미스가 나는 경우 메모리에서 데이터를 가져오기 때문에 느리다

캐시히트 상태일 때 데이터를 읽는 동작이 아니라 쓰는( 데이터의 변경) 동작이 발생한다면 두가지 정책을 기준으로 동작한다

1. Write Through 정책

    메인 메모리를 바로 업데이트

    단순하며 캐시와 메인 메모리의 일관성을 유지할 수 있지만 매번 메인 메모리를 업데이트 해야하므로 느리다는 단점이 존재한다

1. Write Back 정책

    일단 캐시만 업데이트 하다가, 업데이트 된 데이터가 캐시에서 빠지게 될 때 메모리를 업데이트

    속도는 빠르지만 캐시와 메모리의 값이 서로 다를 때가 존재한다

    데이터가 변경되었는지 확인하기 위해 캐시 블록마다 변경감지 비트를 추가해야한다

    데이터가 변경되었으면 1 변경되지 않았으면 0 을 입력해 데이터의 변경여부를 확인시켜준다

    ( JPA 의 변경감지 와 비슷한거같음 )

### 캐시의 사례

1. **CDN ( Content Delivery Network )**

    세계 각지에 캐시 서버를 두어 전송속도를 높이고 부하를 분산하는 시스템

    [ 예시 ]

    YouTube 의 메인 서버는 미국에 존재함

    한국과 미국을 잇는 인터넷 회선은 매우 비싸고 용량을 늘리기 어렵다

    구글은 각 통신사마다 Google Global Cache를 두어 인기 있는 YouTube 동영상은 미국 서버까지 접속할 필요없이 국내 서버에서 처리하도록 함

    비싼 국제 회선 비용이 절감되고 버퍼링이 줄어 고화질 서비스의 이용 경험이 개선됨

2. **웹 브라우저 캐시**

    네트워크를 통해 데이터를 가져오는 것은 하드디스크보다 느릴 경우가 있음

    그래서 웹 브라우저는 웹 페이지에 접속할 때 HTML, CSS , JS , img 등을 하드디스크나 메모리에 캐싱해 두었다가 다음 번에 다시 접속할 때 이를 재활용함

    웹 서버 또한 웹 브라우저로 줘야할 내용이 바뀌지 않는 경우가 많기 때문에 서버에서 생성한 HTML을 캐싱해두었다가 다음번 요청때 이를 재활용한다

    이와 유사하게 클라이언트에서 자주 요청받는 내용은 웹 서버로 전달하지 않고 프록시 서버에 캐싱해둔 데이터를 바로 제공하기도 한다

3. **스프링부트 캐시**

```java
//의존성 추가
implementation 'org.springframework.book:spring-boot-starter-chache'

//@EnableCaching 실행 클래스에 추가
@SpringBootApplication
@EnableChaching
public class SpringCacheApplication(){
.....
}

//자주 사용하는 쿼리메소드에 @Cacheable(value = "{Entity}") 추가
@Cacheable(value="book")
public List<Book> getBookList(String name){
	return bookRepository.findByName(name);
}
```

결과값을 캐시에 올려 빠르게 반환 가능

JPA 영속성 컨텍스트가 1차캐시에 올려놓고 사용하는거라 JPA 사용하면 사용하지 않아도 됨

4. **Redis ( Remote Dictionaty Server)**

    메모리 기반 오픈소스 NoSQL DBMS의 일종으로 웹 서비스에서 캐싱을 위해 많이 사용

    Java의 HashMap<Key, Value> 형태로 데이터가 저장되어있는 서버

    별도의 쿼리없이 Key를 통해 빠르게 결과를 가져오는 것이 가능

    서버 재부팅시 메모리의 데이터가 휘발되지 않게 데이터를 하드디스크에 기록 가능
